{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCh88cVNyTQtnH3OrZ2BxN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aarav2703/mnist-digit-classification/blob/main/dig_recog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ioCijtEgKdkn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, array_to_img\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape and normalize the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Check the shape of the data\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBySkCfyKfMl",
        "outputId": "a448002d-fe8b-4985-8d4b-580d8480c370"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "y_train shape: (60000, 10)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "y_test shape: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = build_cnn()\n",
        "cnn_model.summary()\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the CNN model\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(x_test, y_test)\n",
        "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELOU4pYUK-P4",
        "outputId": "4f7064a6-e1a4-4998-d42d-fae857678535"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 13, 13, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 13, 13, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 5, 5, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 5, 5, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 1600)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 128)               204928    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225034 (879.04 KB)\n",
            "Trainable params: 225034 (879.04 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "469/469 [==============================] - 4s 6ms/step - loss: 0.3664 - accuracy: 0.8843 - val_loss: 0.0710 - val_accuracy: 0.9767\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1251 - accuracy: 0.9618 - val_loss: 0.0472 - val_accuracy: 0.9845\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0958 - accuracy: 0.9718 - val_loss: 0.0345 - val_accuracy: 0.9889\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0791 - accuracy: 0.9766 - val_loss: 0.0332 - val_accuracy: 0.9889\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0688 - accuracy: 0.9790 - val_loss: 0.0274 - val_accuracy: 0.9907\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0614 - accuracy: 0.9821 - val_loss: 0.0276 - val_accuracy: 0.9914\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0578 - accuracy: 0.9828 - val_loss: 0.0257 - val_accuracy: 0.9918\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0519 - accuracy: 0.9841 - val_loss: 0.0234 - val_accuracy: 0.9923\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0504 - accuracy: 0.9844 - val_loss: 0.0236 - val_accuracy: 0.9927\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0460 - accuracy: 0.9861 - val_loss: 0.0222 - val_accuracy: 0.9937\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9937\n",
            "CNN Accuracy: 0.9937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Train the CNN model with augmented data\n",
        "cnn_model.fit(datagen.flow(x_train, y_train, batch_size=128), epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the CNN model after augmentation\n",
        "cnn_loss, cnn_accuracy = cnn_model.evaluate(x_test, y_test)\n",
        "print(f\"CNN Accuracy after Augmentation: {cnn_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql1cWNySK_tq",
        "outputId": "23de51cc-2955-49d9-f7f9-88a442368be8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 18s 37ms/step - loss: 0.2017 - accuracy: 0.9403 - val_loss: 0.0221 - val_accuracy: 0.9912\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 20s 42ms/step - loss: 0.1358 - accuracy: 0.9587 - val_loss: 0.0198 - val_accuracy: 0.9926\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1215 - accuracy: 0.9636 - val_loss: 0.0240 - val_accuracy: 0.9915\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 18s 39ms/step - loss: 0.1103 - accuracy: 0.9671 - val_loss: 0.0172 - val_accuracy: 0.9941\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.1012 - accuracy: 0.9695 - val_loss: 0.0157 - val_accuracy: 0.9946\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.0979 - accuracy: 0.9706 - val_loss: 0.0175 - val_accuracy: 0.9938\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0917 - accuracy: 0.9731 - val_loss: 0.0171 - val_accuracy: 0.9944\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 18s 38ms/step - loss: 0.0917 - accuracy: 0.9730 - val_loss: 0.0168 - val_accuracy: 0.9944\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 19s 40ms/step - loss: 0.0846 - accuracy: 0.9749 - val_loss: 0.0161 - val_accuracy: 0.9943\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 17s 37ms/step - loss: 0.0815 - accuracy: 0.9751 - val_loss: 0.0165 - val_accuracy: 0.9941\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9941\n",
            "CNN Accuracy after Augmentation: 0.9941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the data for KNN\n",
        "x_train_flat = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test_flat = x_test.reshape(x_test.shape[0], -1)\n",
        "\n",
        "# KNN model\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(x_train_flat, np.argmax(y_train, axis=1))\n",
        "knn_predictions = knn.predict(x_test_flat)\n",
        "\n",
        "# Evaluate KNN model\n",
        "knn_accuracy = accuracy_score(np.argmax(y_test, axis=1), knn_predictions)\n",
        "print(f\"KNN Accuracy: {knn_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnjVYmNeLBXG",
        "outputId": "94c34548-12ff-4353-bbb4-a726375eb2c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.9705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PSVM model with probability enabled\n",
        "psvm = SVC(kernel='poly', degree=3, probability=True)\n",
        "psvm.fit(x_train_flat, np.argmax(y_train, axis=1))\n",
        "psvm_predictions = psvm.predict_proba(x_test_flat)\n",
        "\n",
        "# Evaluate PSVM model\n",
        "psvm_accuracy = accuracy_score(np.argmax(y_test, axis=1), np.argmax(psvm_predictions, axis=1))\n",
        "print(f\"PSVM Accuracy: {psvm_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNn4Dix6LC3O",
        "outputId": "24504df4-019b-4e6c-9318-ba75170213ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PSVM Accuracy: 0.9788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_nn():\n",
        "    model = Sequential([\n",
        "        Flatten(input_shape=(28, 28, 1)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "nn_model = build_nn()\n",
        "nn_model.summary()\n",
        "\n",
        "# Train the Neural Network\n",
        "nn_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate Neural Network model\n",
        "nn_loss, nn_accuracy = nn_model.evaluate(x_test, y_test)\n",
        "print(f\"Neural Network Accuracy: {nn_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9__fSAM1ML9m",
        "outputId": "fa14cd69-55f5-43d0-c7b9-d38a867aee95"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               100480    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 109386 (427.29 KB)\n",
            "Trainable params: 109386 (427.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2816 - accuracy: 0.9167 - val_loss: 0.1267 - val_accuracy: 0.9616\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1328 - accuracy: 0.9592 - val_loss: 0.1065 - val_accuracy: 0.9695\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1024 - accuracy: 0.9686 - val_loss: 0.0980 - val_accuracy: 0.9693\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0880 - accuracy: 0.9728 - val_loss: 0.0800 - val_accuracy: 0.9752\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0763 - accuracy: 0.9754 - val_loss: 0.0788 - val_accuracy: 0.9771\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0681 - accuracy: 0.9777 - val_loss: 0.0758 - val_accuracy: 0.9771\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0598 - accuracy: 0.9800 - val_loss: 0.0876 - val_accuracy: 0.9754\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.0750 - val_accuracy: 0.9783\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0546 - accuracy: 0.9814 - val_loss: 0.0763 - val_accuracy: 0.9796\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0491 - accuracy: 0.9831 - val_loss: 0.0800 - val_accuracy: 0.9774\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0800 - accuracy: 0.9774\n",
            "Neural Network Accuracy: 0.9774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize function\n",
        "def resize_images(images, new_size):\n",
        "    resized_images = np.zeros((images.shape[0], new_size[0], new_size[1], 3))\n",
        "    for i in range(images.shape[0]):\n",
        "        img = array_to_img(images[i])\n",
        "        img = img.resize(new_size)\n",
        "        resized_images[i] = img_to_array(img)\n",
        "    return resized_images\n",
        "\n",
        "# Resize MNIST images to 32x32 and repeat the grayscale channel to fit VGG16 input\n",
        "x_train_resized = resize_images(np.repeat(x_train, 3, axis=-1), (32, 32))\n",
        "x_test_resized = resize_images(np.repeat(x_test, 3, axis=-1), (32, 32))\n",
        "\n",
        "# Load pre-trained VGG16 model + higher level layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "\n",
        "# Freeze the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers on top of VGG16\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the final model\n",
        "transfer_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "transfer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the transfer learning model\n",
        "transfer_model.fit(x_train_resized, y_train, epochs=10, validation_data=(x_test_resized, y_test))\n",
        "\n",
        "# Evaluate the transfer learning model\n",
        "transfer_loss, transfer_accuracy = transfer_model.evaluate(x_test_resized, y_test)\n",
        "print(f\"Transfer Learning (VGG16) Accuracy: {transfer_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSfLDtZ_MNs3",
        "outputId": "bedd38e0-e129-4bd8-ebc1-251f2cdcfcd1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.8619 - accuracy: 0.7943 - val_loss: 0.2453 - val_accuracy: 0.9171\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3673 - accuracy: 0.8834 - val_loss: 0.2018 - val_accuracy: 0.9362\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3214 - accuracy: 0.8982 - val_loss: 0.1868 - val_accuracy: 0.9407\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2993 - accuracy: 0.9050 - val_loss: 0.1798 - val_accuracy: 0.9439\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2747 - accuracy: 0.9125 - val_loss: 0.1817 - val_accuracy: 0.9430\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2647 - accuracy: 0.9154 - val_loss: 0.1696 - val_accuracy: 0.9464\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2527 - accuracy: 0.9196 - val_loss: 0.1625 - val_accuracy: 0.9498\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2441 - accuracy: 0.9219 - val_loss: 0.1576 - val_accuracy: 0.9517\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2348 - accuracy: 0.9255 - val_loss: 0.1676 - val_accuracy: 0.9460\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2381 - accuracy: 0.9257 - val_loss: 0.1588 - val_accuracy: 0.9518\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1588 - accuracy: 0.9518\n",
            "Transfer Learning (VGG16) Accuracy: 0.9518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to get model predictions\n",
        "def get_predictions(model, data, model_type='keras'):\n",
        "    if model_type == 'keras':\n",
        "        return model.predict(data)\n",
        "    else:\n",
        "        return model.predict_proba(data)\n",
        "\n",
        "# Predictions from individual models\n",
        "cnn_predictions = get_predictions(cnn_model, x_test)\n",
        "nn_predictions = get_predictions(nn_model, x_test)\n",
        "knn_predictions = knn.predict_proba(x_test_flat)\n",
        "psvm_predictions = psvm.predict_proba(x_test_flat)\n",
        "\n",
        "# Convert Keras model predictions to match the shape of scikit-learn predictions\n",
        "cnn_predictions = cnn_predictions.reshape(-1, 10)\n",
        "nn_predictions = nn_predictions.reshape(-1, 10)\n",
        "\n",
        "# Averaging the predictions (soft voting)\n",
        "ensemble_predictions = (cnn_predictions + nn_predictions + knn_predictions + psvm_predictions) / 4.0\n",
        "ensemble_predictions = np.argmax(ensemble_predictions, axis=1)\n",
        "\n",
        "# Evaluate ensemble model\n",
        "ensemble_accuracy = accuracy_score(np.argmax(y_test, axis=1), ensemble_predictions)\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UunNRsyrRQrJ",
        "outputId": "10faef27-f611-4210-bc0e-dde290ccb294"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 4ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Ensemble Accuracy: 0.9892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add code for modern architectures\n",
        "from tensorflow.keras.applications import ResNet50, InceptionV3\n",
        "\n",
        "# Load ResNet50\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
        "# Freeze layers\n",
        "for layer in resnet_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = resnet_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create model\n",
        "resnet_model_final = Model(inputs=resnet_model.input, outputs=predictions)\n",
        "resnet_model_final.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "resnet_model_final.fit(x_train_resized, y_train, epochs=10, validation_data=(x_test_resized, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "resnet_loss, resnet_accuracy = resnet_model_final.evaluate(x_test_resized, y_test)\n",
        "print(f\"ResNet50 Accuracy: {resnet_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csKPD8YPXfRe",
        "outputId": "c158101d-81d5-49c2-e506-8761d884ff2e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 27s 12ms/step - loss: 0.5817 - accuracy: 0.8120 - val_loss: 0.2121 - val_accuracy: 0.9298\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.3718 - accuracy: 0.8791 - val_loss: 0.1737 - val_accuracy: 0.9448\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3262 - accuracy: 0.8957 - val_loss: 0.1919 - val_accuracy: 0.9402\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.3086 - accuracy: 0.9002 - val_loss: 0.1619 - val_accuracy: 0.9477\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2882 - accuracy: 0.9072 - val_loss: 0.1620 - val_accuracy: 0.9499\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2758 - accuracy: 0.9107 - val_loss: 0.1459 - val_accuracy: 0.9540\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 25s 13ms/step - loss: 0.2587 - accuracy: 0.9179 - val_loss: 0.1484 - val_accuracy: 0.9530\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 22s 12ms/step - loss: 0.2537 - accuracy: 0.9179 - val_loss: 0.1417 - val_accuracy: 0.9542\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2386 - accuracy: 0.9224 - val_loss: 0.1462 - val_accuracy: 0.9563\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 24s 13ms/step - loss: 0.2355 - accuracy: 0.9245 - val_loss: 0.1503 - val_accuracy: 0.9527\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 0.1503 - accuracy: 0.9527\n",
            "ResNet50 Accuracy: 0.9527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add code for performance analysis\n",
        "import time\n",
        "\n",
        "def measure_performance(model, data, labels):\n",
        "    start_time = time.time()\n",
        "    loss, accuracy = model.evaluate(data, labels, verbose=0)\n",
        "    end_time = time.time()\n",
        "    return accuracy, end_time - start_time\n",
        "\n",
        "cnn_accuracy, cnn_time = measure_performance(cnn_model, x_test, y_test)\n",
        "nn_accuracy, nn_time = measure_performance(nn_model, x_test, y_test)\n",
        "ensemble_accuracy, ensemble_time = measure_performance(nn_model, x_test, y_test)  # Using nn_model as a placeholder\n",
        "\n",
        "print(f\"CNN Accuracy: {cnn_accuracy:.4f}, Time: {cnn_time:.4f}s\")\n",
        "print(f\"NN Accuracy: {nn_accuracy:.4f}, Time: {nn_time:.4f}s\")\n",
        "print(f\"Ensemble Accuracy: {ensemble_accuracy:.4f}, Time: {ensemble_time:.4f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEOZvnK0eRDv",
        "outputId": "7c598079-c3ae-4440-8c7d-aa0df2f6ec53"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Accuracy: 0.9941, Time: 1.4522s\n",
            "NN Accuracy: 0.9774, Time: 1.1251s\n",
            "Ensemble Accuracy: 0.9774, Time: 0.7169s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add code for model deployment\n",
        "import tensorflow as tf\n",
        "\n",
        "# Save the model\n",
        "cnn_model.save('cnn_model.h5')\n",
        "\n",
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('cnn_model.h5')\n",
        "\n",
        "# Verify the loaded model\n",
        "loss, accuracy = loaded_model.evaluate(x_test, y_test)\n",
        "print(f\"Loaded model accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWFpqboUgOvO",
        "outputId": "938fe860-0c65-498f-fd93-98fdfcdc37b1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0165 - accuracy: 0.9941\n",
            "Loaded model accuracy: 0.9941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Add code for edge computing\n",
        "import tensorflow as tf\n",
        "import tensorflow.lite as tflite\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tflite.TFLiteConverter.from_keras_model(cnn_model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model\n",
        "with open('cnn_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "# Load and run the model on a TFLite interpreter\n",
        "interpreter = tflite.Interpreter(model_path='cnn_model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the model on random input data\n",
        "input_data = np.array(np.random.random_sample(input_details[0]['shape']), dtype=np.float32)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the results\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpUvQjfsgbFc",
        "outputId": "1528bcda-9b45-40f7-b1d4-fea1f8ce6775"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f64902a2170> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7f64902a2170>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function trace_model_call.<locals>._wrapped_model at 0x7f64902a2170> and will run it as-is.\n",
            "Cause: Unable to locate the source code of <function trace_model_call.<locals>._wrapped_model at 0x7f64902a2170>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "[[5.1477941e-06 1.0067246e-07 1.5272357e-04 1.1641455e-04 1.2558603e-06\n",
            "  4.6983416e-05 4.5607601e-05 1.3279307e-08 9.9956852e-01 6.3257226e-05]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt\n"
      ],
      "metadata": {
        "id": "C7rvrkGGgeYQ"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}